{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import beta\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patches\n",
    "import pandas as pd\n",
    "from intervaltree import Interval, IntervalTree\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "plt.rcParams['pdf.use14corefonts'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSIZE = {'1': 249250621, '2': 243199373, '3': 198022430, '4': 191154276, '5': 180915260, '6': 171115067, '7': 159138663,\n",
    "         '8': 146364022,\n",
    "         '9': 141213431, '10': 135534747, '11': 135006516, '12': 133851895, '13': 115169878, '14': 107349540,\n",
    "         '15': 102531392,\n",
    "         '16': 90354753, '17': 81195210, '18': 78077248, '19': 59128983, '20': 63025520, '21': 48129895, '22': 51304566,\n",
    "         'X': 156040895, 'Y': 57227415, '23': 156040895, '24': 57227415}\n",
    "cluster_color_map = {'0': '#808080', '1': '#278C18', '2': '#67C8F3', '3': '#F88B10', '4': '#103129', '5': '#5D77FE',\n",
    "                     '6': '#98161A',\n",
    "                     '7': '#68ECAC', '8': '#F98E87', '9': '#371230', '10': '#535216', '11': '#F72424', '12': '#004F72',\n",
    "                     '13': '#F34184', '14': '#3CB9B3', '15': '#B9B1F3', '16': '#8B2243', '17': '#B229BA',\n",
    "                     '18': '#3A92E7',\n",
    "                     '19': '#829F15', '20': '#A15BF3', '21': '#833D11', '22': '#F84B51', '23': '#204B20',\n",
    "                     '24': '#2D6D74',\n",
    "                     '25': '#FFA9C7', '26': '#37B371', '27': '#222A03', '28': '#3879A6', '29': '#AC3C0F',\n",
    "                     '30': '#734CCC',\n",
    "                     '31': '#153D49', '32': '#43154A', '33': '#7B5870', '34': '#576A2E', '35': '#25423A',\n",
    "                     '36': '#844F3E',\n",
    "                     '37': '#473A20', '38': '#3B6872', '39': '#2E6B5A', '40': '#544449', '41': '#5A617C',\n",
    "                     '42': '#79424C',\n",
    "                     '43': '#685D30', '44': '#314352', '45': '#475F41', '46': '#7F552C', '47': '#584F5C',\n",
    "                     '48': '#DCD4C2',\n",
    "                     '49': '#232224', '50': '#C8DCE0', '51': '#495145', '52': '#E0C7CE', '53': '#787F71',\n",
    "                     '54': '#8E94A6',\n",
    "                     '55': '#99A79C', '56': '#A28B91', '57': '#000000'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_total_cn_dict = {'copy_neutral': 2, 'single_gain': 3, 'double_gain': 4, 'single_loss': 1, 'double_loss': 0}\n",
    "basic_allelic_cn_dict = {'copy_neutral': (0, 2), 'single_gain': (1, 2), 'double_gain': (2, 2), 'single_loss': (0, 1), 'double_loss': (0, 0)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CCFs from the cluster_ccfs file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_ccfs(cluster_ccfs, sample_list):\n",
    "    sample_ccfs = {sample_name: {} for sample_name in sample_list}\n",
    "    for (sample_name, cluster), sample_df in cluster_ccfs.groupby(['Sample_ID', 'Cluster_ID']):\n",
    "        sample_ccfs[sample_name][str(cluster)] = sample_df.squeeze()['postDP_ccf_mean']\n",
    "\n",
    "    return sample_ccfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create interval trees for each chromosome for a patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_contig_trees(acs_dfs, sample_list):\n",
    "    chromosomes = pd.unique(acs_dfs[0]['Chromosome'])\n",
    "    contig_tree = {str(chrom): IntervalTree() for chrom in chromosomes} # Initialize overall patient contig tree\n",
    "    for seg_df, sample_name in zip(acs_dfs, sample_list): # Iterate through each sample\n",
    "        for chrom, chrom_seg_df in seg_df.groupby('Chromosome'): # Iterate through each chromosome\n",
    "            chrom_tree = IntervalTree( # Create sample interval trees for each chromosome for each sample of the patient\n",
    "                Interval(row['Start.bp'], row['End.bp'], {sample_name: (row['mu.minor'], row['mu.major'])}) for i, row # Each interval contains seg boundaries, sample name, and copy number\n",
    "                in chrom_seg_df.iterrows() if pd.notna(row['mu.minor']) and pd.notna(row['mu.major']))\n",
    "            contig_tree[str(chrom)].update(chrom_tree) # Add intervals to overall patient contig tree\n",
    "    # Merge interval trees for the same chromosome across samples\n",
    "    for chrom in contig_tree:\n",
    "        contig_tree[chrom].split_overlaps() # Split all intervals at the point where they overlap with another interval\n",
    "        contig_tree[chrom].merge_equals(data_reducer=lambda o, n: dict(o, **n)) # Merge intervals with the same boundaries; the final merged information will contain copy numbers for all samples\n",
    "        for interval in contig_tree[chrom].copy():\n",
    "            if len(interval.data) != len(sample_list):\n",
    "                contig_tree[chrom].remove(interval) # Remove any intervals that aren't covered by all samples\n",
    "\n",
    "    return contig_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign segs to clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_segs(contig_tree, sample_ccfs, hets_dfs, purities, ploidies):\n",
    "    seg_assignments = {chrom: IntervalTree() for chrom in contig_tree}\n",
    "    seg_total_cn = {chrom: {} for chrom in contig_tree}\n",
    "    seg_allelic_cn = {chrom: {} for chrom in contig_tree}\n",
    "    seg_ccf = {chrom: {} for chrom in contig_tree}\n",
    "    ccf_grid = np.arange(101) / 100\n",
    "    for chrom, tree in contig_tree.items(): # Iterate through each chromosome\n",
    "        for seg in tree: # Iterate through each seg\n",
    "            start = seg.begin\n",
    "            end = seg.end\n",
    "            mu_minor = np.array([mu[0] for mu in seg.data.values()]) # Expected values of minor allele copy numbers\n",
    "            mu_major = np.array([mu[1] for mu in seg.data.values()]) # Expected values of major allele copy numbers\n",
    "            if all((mu_minor >= .85) & (mu_minor <= 1.15)) and all((mu_major >= .85) & (mu_major <= 1.15)): # If both copy numbers are around 1 for all samples, no cnv is called\n",
    "                seg_assignments[chrom][start:end] = '0'\n",
    "                seg_total_cn[chrom][(start, end)] = 2\n",
    "                seg_allelic_cn[chrom][(start, end)] = (1, 1)\n",
    "                continue\n",
    "            classification = 'copy_neutral' # Default is CNLOH\n",
    "            if any(mu_major > 1.15) and all(mu_major >= .85) and all((mu_minor <= 1.15) & (mu_minor >= .85)): # Single gain if only major allele is gained and no allele is ever lost\n",
    "                classification = 'single_gain'\n",
    "            if any(mu_major > 1.15) and all(mu_major >= .85) and any(mu_minor > 1.15) and all(mu_minor >= .85): # Double gain if both alleles are gained and no allele is ever lost\n",
    "                classification = 'double_gain'\n",
    "            if any(mu_minor < .85) and all(mu_minor <= 1.15) and all((mu_major >= .85) & (mu_major <= 1.15)): # Single loss if only minor allele is lost and no allele is ever gained\n",
    "                classification = 'single_loss'\n",
    "            if any(mu_minor < .85) and all(mu_minor <= 1.15) and any(mu_major < .85) and all(mu_major <= 1.15): # Double loss if both alleles are lost and no allele is ever gained\n",
    "                classification = 'double_loss'\n",
    "            no_hets = False\n",
    "            sample_likelihoods = {}\n",
    "            sample_ccf_dict = {}\n",
    "            for sample, hets_df, purity, ploidy in zip(sample_ccfs, hets_dfs, purities, ploidies): # For each sample get CCFs and assignment likelihoods for every cluster\n",
    "                clonal_likelihoods = {}\n",
    "                # For double gains and double losses, both alleles have the same copy number so we can't use het AF information\n",
    "                if classification == 'double_gain':\n",
    "                    ccf = seg.data[sample][0] - 1 # CCF is copy number of double gain - 1\n",
    "                    sample_ccf_dict[sample] = ccf\n",
    "                    for cluster in sample_ccfs[sample]:\n",
    "                        clonal_likelihoods[cluster] = np.log((1 - abs(ccf - sample_ccfs[sample][cluster])) ** 2) # Likelihood is set to 1 - mean squared error; not accurate but we're only taking the max so it doens't really matter\n",
    "                elif classification == 'double_loss':\n",
    "                    ccf = 1 - seg.data[sample][0] # CCF is 1 - copy number of double loss\n",
    "                    sample_ccf_dict[sample] = ccf\n",
    "                    for cluster in sample_ccfs[sample]:\n",
    "                        clonal_likelihoods[cluster] = np.log((1 - abs(ccf - sample_ccfs[sample][cluster])) ** 2)\n",
    "                # For single gains and single losses we use het info\n",
    "                else:\n",
    "                    hets = hets_df.loc[(hets_df['CONTIG'].astype(str) == chrom) & \\\n",
    "                                       hets_df['POSITION'].astype(int).between(start, end)]\n",
    "                    ref_counts = hets['REF_COUNT'].values\n",
    "                    alt_counts = hets['ALT_COUNT'].values\n",
    "                    # Posterior distribution for true allele ratio given ref and alt counts for all hets on seg\n",
    "                    posterior_het_split = np.sum(np.log(10e-25 + (\n",
    "                                0.5 * beta.pdf(np.expand_dims(np.linspace(0, 1, 101), axis=1), ref_counts + 1,\n",
    "                                               alt_counts + 1)) +\n",
    "                                                        (0.5 * beta.pdf(np.expand_dims(np.linspace(0, 1, 101), axis=1),\n",
    "                                                                        alt_counts + 1, ref_counts + 1))), axis=1)\n",
    "\n",
    "                    posterior_het_split = posterior_het_split - scipy.special.logsumexp(posterior_het_split)\n",
    "                    if hets.empty: # If no hets, don't call anything\n",
    "                        no_hets = True\n",
    "                        break\n",
    "                    ccf_dist = np.empty(101, dtype=np.float64)\n",
    "                    if classification == 'single_gain':\n",
    "                        for cluster, ccf in sample_ccfs[sample].items():\n",
    "                            # Calculate predicted allele ratio given cluster CCF\n",
    "                            num = .5 * (1 - purity) * 2 + 2 * purity * ccf + 1 * (1 - ccf) * purity # Amount of allele 1 in normal cells + amount of allele 1 in cluster + amount of allele 1 in tumor cells but outside cluster\n",
    "                            denom = (2 * (1 - purity) + purity * (ccf * 3 + (1 - ccf) * 2)) # Amount of allele 1 and allele 2 in normal cells + amount of allele 1 and allele 2 in tumor cells\n",
    "                            gain = num / denom # Predicted allele ratio given CCF\n",
    "\n",
    "                            num = .5 * (1 - purity) * 2 + 1 * purity * ccf + 1 * (1 - ccf) * purity\n",
    "                            denom = (2 * (1 - purity) + purity * (ccf * 3 + (1 - ccf) * 2))\n",
    "                            gain_other = num / denom # 1 - predicted allele ratio; this is actually unnecessary since the posterior distribution is symmetrical, but it doesn't matter\n",
    "\n",
    "                            gain = int(np.around(gain, decimals=2) * 100) # Round to the nearst hundredth\n",
    "                            gain_other = int(np.around(gain_other, decimals=2) * 100)\n",
    "\n",
    "                            lh_clone = posterior_het_split[gain] + posterior_het_split[gain_other]\n",
    "                            clonal_likelihoods[cluster] = lh_clone\n",
    "                        # Calculated CCF distribution\n",
    "                        for i, ccf in enumerate(ccf_grid):\n",
    "                            num = .5 * (1 - purity) * 2 + 2 * purity * ccf + 1 * (1 - ccf) * purity\n",
    "                            denom = (2 * (1 - purity) + purity * (ccf * 3 + (1 - ccf) * 2))\n",
    "                            gain = num / denom\n",
    "\n",
    "                            num = .5 * (1 - purity) * 2 + 1 * purity * ccf + 1 * (1 - ccf) * purity\n",
    "                            denom = (2 * (1 - purity) + purity * (ccf * 3 + (1 - ccf) * 2))\n",
    "                            gain_other = num / denom\n",
    "\n",
    "                            gain = int(np.around(gain, decimals=2) * 100)\n",
    "                            gain_other = int(np.around(gain_other, decimals=2) * 100)\n",
    "\n",
    "                            lh = np.logaddexp(posterior_het_split[gain], posterior_het_split[gain_other])\n",
    "                            ccf_dist[i] = lh\n",
    "                        ccf_dist = ccf_dist - scipy.special.logsumexp(ccf_dist)\n",
    "                    elif classification == 'single_loss': # Similar process for single loss and CNLOH\n",
    "                        for cluster, ccf in sample_ccfs[sample].items():\n",
    "                            num = .5 * (1 - purity) * 2 + 0 * purity * ccf + 1 * (1 - ccf) * purity\n",
    "                            denom = (2 * (1 - purity) + purity * (ccf * 1 + (1 - ccf) * 2))\n",
    "                            deletion = num / denom\n",
    "\n",
    "                            num = .5 * (1 - purity) * 2 + 1 * purity * ccf + 1 * (1 - ccf) * purity\n",
    "                            denom = (2 * (1 - purity) + purity * (ccf * 1 + (1 - ccf) * 2))\n",
    "                            deletion_other = num / denom\n",
    "\n",
    "                            deletion = int(np.around(deletion, decimals=2) * 100)\n",
    "                            deletion_other = int(np.around(deletion_other, decimals=2) * 100)\n",
    "\n",
    "                            lh_clone = posterior_het_split[deletion] + posterior_het_split[deletion_other]\n",
    "                            clonal_likelihoods[cluster] = lh_clone\n",
    "                        for i, ccf in enumerate(ccf_grid):\n",
    "                            num = .5 * (1 - purity) * 2 + 0 * purity * ccf + 1 * (1 - ccf) * purity\n",
    "                            denom = (2 * (1 - purity) + purity * (ccf * 1 + (1 - ccf) * 2))\n",
    "                            deletion = num / denom\n",
    "\n",
    "                            num = .5 * (1 - purity) * 2 + 1 * purity * ccf + 1 * (1 - ccf) * purity\n",
    "                            denom = (2 * (1 - purity) + purity * (ccf * 1 + (1 - ccf) * 2))\n",
    "                            deletion_other = num / denom\n",
    "\n",
    "                            deletion = int(np.around(deletion, decimals=2) * 100)\n",
    "                            deletion_other = int(np.around(deletion_other, decimals=2) * 100)\n",
    "\n",
    "                            lh = np.logaddexp(posterior_het_split[deletion], posterior_het_split[deletion_other])\n",
    "                            ccf_dist[i] = lh\n",
    "                        ccf_dist = ccf_dist - scipy.special.logsumexp(ccf_dist)\n",
    "                    elif classification == 'copy_neutral':\n",
    "                        for cluster, ccf in sample_ccfs[sample].items():\n",
    "                            num = .5 * (1 - purity) * 2 + 0 * purity * ccf + (1 - ccf) * purity\n",
    "                            denom = (2 * (1 - purity) + purity * (ccf * 2 + (1 - ccf) * 2))\n",
    "                            cnloh = num / denom\n",
    "\n",
    "                            num = .5 * (1 - purity) * 2 + 2 * purity * ccf + (1 - ccf) * purity\n",
    "                            denom = (2 * (1 - purity) + purity * (ccf * 2 + (1 - ccf) * 2))\n",
    "                            cnloh_other = num / denom\n",
    "\n",
    "                            cnloh = int(np.around(cnloh, decimals=2) * 100)\n",
    "                            cnloh_other = int(np.around(cnloh_other, decimals=2) * 100)\n",
    "\n",
    "                            lh_clone = posterior_het_split[cnloh] + posterior_het_split[cnloh_other]\n",
    "                            clonal_likelihoods[cluster] = lh_clone\n",
    "                        for i, ccf in enumerate(ccf_grid):\n",
    "                            num = .5 * (1 - purity) * 2 + 0 * purity * ccf + (1 - ccf) * purity\n",
    "                            denom = (2 * (1 - purity) + purity * (ccf * 2 + (1 - ccf) * 2))\n",
    "                            cnloh = num / denom\n",
    "\n",
    "                            num = .5 * (1 - purity) * 2 + 2 * purity * ccf + (1 - ccf) * purity\n",
    "                            denom = (2 * (1 - purity) + purity * (ccf * 2 + (1 - ccf) * 2))\n",
    "                            cnloh_other = num / denom\n",
    "\n",
    "                            cnloh = int(np.around(cnloh, decimals=2) * 100)\n",
    "                            cnloh_other = int(np.around(cnloh_other, decimals=2) * 100)\n",
    "\n",
    "                            lh = np.logaddexp(posterior_het_split[cnloh], posterior_het_split[cnloh_other])\n",
    "                            ccf_dist[i] = lh\n",
    "                        ccf_dist = ccf_dist - scipy.special.logsumexp(ccf_dist)\n",
    "                    ccf_dist = np.exp(ccf_dist)\n",
    "                    sample_ccf_dict[sample] = np.sum(ccf_grid * ccf_dist)\n",
    "                sample_likelihoods[sample] = clonal_likelihoods\n",
    "            if no_hets: # If any of the samples has no het information, don't call the CNV\n",
    "                seg_assignments[chrom][start:end] = '0'\n",
    "                seg_total_cn[chrom][(start, end)] = 2\n",
    "                seg_allelic_cn[chrom][(start, end)] = (1, 1)\n",
    "            else:\n",
    "                sample_likelihoods = pd.DataFrame(sample_likelihoods)\n",
    "                sample_likelihoods -= logsumexp(sample_likelihoods, axis=0)\n",
    "                sample_likelihoods_sum = sample_likelihoods.sum(axis=1) # Multiply likelihoods (adding in log space) across samples\n",
    "                seg_assignments[chrom][start:end] = sample_likelihoods_sum.idxmax()\n",
    "                seg_total_cn[chrom][(start, end)] = basic_total_cn_dict[classification]\n",
    "                seg_allelic_cn[chrom][(start, end)] = basic_allelic_cn_dict[classification]\n",
    "                seg_ccf[chrom][(start, end)] = sample_ccf_dict\n",
    "\n",
    "    return seg_assignments, seg_total_cn, seg_allelic_cn, seg_ccf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hets(seg_assignments, hets_df, fn):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax = plt.gca()\n",
    "    base_start = 0\n",
    "    patch_color = 'white'\n",
    "    chrom_ticks = []\n",
    "    chroms = sorted(seg_assignments, key=lambda k: int(k) if k.isnumeric() else ord(k))\n",
    "\n",
    "    for chrom in chroms:\n",
    "        tree = seg_assignments[chrom]\n",
    "        for seg in tree:\n",
    "            hets = hets_df.loc[\n",
    "                (hets_df['CONTIG'].astype(str) == chrom) & hets_df['POSITION'].astype(int).between(seg.begin, seg.end)]\n",
    "            afs = hets['ALT_COUNT'] / (hets['REF_COUNT'] + hets['ALT_COUNT'])\n",
    "            color = cluster_color_map[seg.data]\n",
    "            ax.scatter(hets['POSITION'] + base_start, afs, color=color)\n",
    "        p = patches.Rectangle((base_start, -10), CSIZE[chrom], 100, fill=True, facecolor=patch_color, edgecolor=None,\n",
    "                              alpha=.1)  # Background\n",
    "        ax.add_patch(p)\n",
    "        patch_color = 'gray' if patch_color == 'white' else 'white'\n",
    "        chrom_ticks.append(base_start + CSIZE[chrom] / 2)\n",
    "        base_start += CSIZE[chrom]\n",
    "    ax.set_xticks(chrom_ticks)\n",
    "    ax.set_xticklabels(chroms, fontsize=6)\n",
    "    ax.set_xlim(0, base_start)\n",
    "    ax.set_xlabel(\"Chromosome\")\n",
    "    ax.set_ylabel(\"Allele Fraction\")\n",
    "    ax.set_ylim(0, 1)\n",
    "    plt.setp(ax.spines.values(), color='gray', lw=.5)\n",
    "    plt.setp([ax.get_xticklines(), ax.get_yticklines()], color='gray', lw=.5)\n",
    "    plt.savefig(fn)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_absolute(sample_name, purity, ploidy, seg_assignments, contig_trees, seg, fn):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax = plt.gca()\n",
    "    base_start = 0\n",
    "    chrom_ticks = []\n",
    "    patch_color = 'white'\n",
    "    chroms = sorted(contig_trees, key=lambda k: int(k) if k.isnumeric() else ord(k))\n",
    "    for chrom in chroms:\n",
    "        contig_tree = contig_trees[chrom]\n",
    "        assign_tree = seg_assignments[chrom]\n",
    "        for contig_seg in contig_tree:\n",
    "            cr1, cr2 = contig_seg.data[sample_name]\n",
    "            for assign_seg in assign_tree[contig_seg.begin:contig_seg.end]:\n",
    "                start = max(assign_seg.begin, contig_seg.begin)\n",
    "                end = min(assign_seg.end, contig_seg.end)\n",
    "#                 if chrom == '1' and cr2 > 4:\n",
    "#                     print('extend')\n",
    "#                     start -= 40000\n",
    "#                     end += 40000\n",
    "                color = cluster_color_map[assign_seg.data]\n",
    "                ax.hlines(cr1, start + base_start, end + base_start, color=color, lw=5)\n",
    "                ax.hlines(cr2, start + base_start, end + base_start, color=color, lw=5)\n",
    "        p = patches.Rectangle((base_start, -10), CSIZE[chrom], 100, fill=True, facecolor=patch_color, edgecolor=None,\n",
    "                              alpha=.1)  # Background\n",
    "        ax.add_patch(p)\n",
    "        patch_color = 'gray' if patch_color == 'white' else 'white'\n",
    "        chrom_ticks.append(base_start + CSIZE[chrom] / 2)\n",
    "        base_start += CSIZE[chrom]\n",
    "    cr_diff = ((seg['mu.minor'] * seg['length']).sum() + (seg['mu.major'] * seg['length']).sum()) / \\\n",
    "              (ploidy * seg['length'].sum() - (1 - 1 / purity) * seg['length'].sum() * 2)\n",
    "    c0 = (cr_diff / purity) - cr_diff\n",
    "    yticks = np.arange(c0, c0 + cr_diff * 2.5, cr_diff)\n",
    "\n",
    "    ax.set_xticks(chrom_ticks)\n",
    "    ax.set_xticklabels(chroms, fontsize=6)\n",
    "    ax.set_xlim(0, base_start)\n",
    "    ax.set_yticks(yticks)\n",
    "    ax.set_yticklabels(range(3), fontsize=16)\n",
    "    ax.set_ylim(yticks[0] - cr_diff, yticks[-1] + cr_diff)\n",
    "    plt.setp(ax.spines.values(), color='gray',lw=.5)\n",
    "    plt.setp([ax.get_xticklines(), ax.get_yticklines()], color='gray',lw=.5)\n",
    "    plt.xlabel(\"Chromosome\")\n",
    "    plt.ylabel(\"Allelic Copy Ratio\")\n",
    "    plt.savefig(fn, facecolor = 'white')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load files and create objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input files required\n",
    "cluster_df = pd.read_csv(PUT CLUSTER CCFS FILE HERE, sep='\\t')\n",
    "samples = [PUT SAMPLE IDS HERE]\n",
    "acs_dfs = [pd.read_csv(acs, sep='\\t') for acs in PUT LIST OF ALLELICCAPSEG FILES HERE]\n",
    "hets_dfs = [pd.read_csv(het, sep='\\t') for het in PUT LIST OF HET FILES HERE]\n",
    "pur = [PUT PURITIES OF SAMPLES HERE]\n",
    "plo = [PUT PLOIDIES OF SAMPLES HERE]\n",
    "\n",
    "sample_ccfs = get_sample_ccfs(cluster_df, samples)\n",
    "contig_trees = make_contig_trees(acs_dfs, samples)\n",
    "seg_assignments, seg_total_cn, seg_allelic_cn, seg_ccf = assign_segs(contig_trees, sample_ccfs, hets_dfs, pur, plo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get input files from Terra through dalmatian\n",
    "import dalmatian\n",
    "\n",
    "#input\n",
    "# patient_list = ['CLL-CRC-0002-0042', 'CLL-CRC-0004','CLL-CRC-0005-0043','CLL-CRC-0006',\n",
    "#                 'CLL-CRC-0007', 'CLL-CRC-0008', 'CLL-CRC-0009', 'CLL-CRC-0010', 'CLL-CRC-0011','CLL-CRC-0012', \n",
    "#                 'CLL-CRC-0014', 'CLL-CRC-0015', 'CLL-CRC-0016', 'CLL-CRC-0017', 'CLL-CRC-0018', 'CLL-CRC-0019', \n",
    "#                'CLL-CRC-0020', 'CLL-CRC-0021', 'CLL-CRC-0036', 'CLL-CRC-0037', 'CLL-CRC-0038','CLL-CRC-0039', \n",
    "#                'CLL-CRC-0040', 'CLL-CRC-0041', 'CLL-CRC-0045']\n",
    "\n",
    "patient_list = ['CLL-CRC-0006',\n",
    "                'CLL-CRC-0007', 'CLL-CRC-0008', 'CLL-CRC-0009', 'CLL-CRC-0010', 'CLL-CRC-0011','CLL-CRC-0012', \n",
    "                'CLL-CRC-0014', 'CLL-CRC-0015', 'CLL-CRC-0016', 'CLL-CRC-0017', 'CLL-CRC-0018', 'CLL-CRC-0019', \n",
    "               'CLL-CRC-0020', 'CLL-CRC-0021', 'CLL-CRC-0036', 'CLL-CRC-0037', 'CLL-CRC-0038','CLL-CRC-0039', \n",
    "               'CLL-CRC-0040', 'CLL-CRC-0041', 'CLL-CRC-0045']\n",
    "\n",
    "workspace ='broad-firecloud-ibmwatson/Getz-IBM-Wu_Fludarabine_Resistance-Analysis'\n",
    "wm = dalmatian.WorkspaceManager(workspace)\n",
    "\n",
    "participants = wm.get_participants()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lil/opt/miniconda3/envs/Fludarabine/lib/python3.9/site-packages/scipy/stats/_continuous_distns.py:645: RuntimeWarning: divide by zero encountered in _beta_pdf\n",
      "  return _boost._beta_pdf(x, a, b)\n",
      "/Users/lil/opt/miniconda3/envs/Fludarabine/lib/python3.9/site-packages/scipy/stats/_continuous_distns.py:645: RuntimeWarning: divide by zero encountered in _beta_pdf\n",
      "  return _boost._beta_pdf(x, a, b)\n",
      "/Users/lil/opt/miniconda3/envs/Fludarabine/lib/python3.9/site-packages/scipy/stats/_continuous_distns.py:645: RuntimeWarning: divide by zero encountered in _beta_pdf\n",
      "  return _boost._beta_pdf(x, a, b)\n",
      "/Users/lil/opt/miniconda3/envs/Fludarabine/lib/python3.9/site-packages/scipy/stats/_continuous_distns.py:645: RuntimeWarning: divide by zero encountered in _beta_pdf\n",
      "  return _boost._beta_pdf(x, a, b)\n",
      "/Users/lil/opt/miniconda3/envs/Fludarabine/lib/python3.9/site-packages/scipy/stats/_continuous_distns.py:645: RuntimeWarning: divide by zero encountered in _beta_pdf\n",
      "  return _boost._beta_pdf(x, a, b)\n"
     ]
    }
   ],
   "source": [
    "for patient in patient_list:\n",
    "    \n",
    "    # In the CRC cohort, the pair set name is the same as the patient\n",
    "    pair_set = patient\n",
    "\n",
    "    cluster_df = pd.read_csv(participants.loc[patient]['cluster_ccfs_Aug2'], sep='\\t')\n",
    "    pairs = wm.get_pairs_in_pair_set(pair_set)\n",
    "    \n",
    "    samples = [i for i,pair in pairs.iterrows()]\n",
    "    pur = [float(i) for i in pairs.wxs_purity.values]\n",
    "    plo =  [float(i) for i in pairs.wxs_ploidy.values]\n",
    "    acs_files = [pair['alleliccapseg_tsv'] for i,pair in pairs.iterrows()]\n",
    "    hets_files = [pair['gatk_het_ad_tumor'] for i,pair in pairs.iterrows()]\n",
    "    \n",
    "    \n",
    "    acs_dfs = [pd.read_csv(acs, sep='\\t') for acs in acs_files]\n",
    "    hets_dfs = [pd.read_csv(het, sep='\\t') for het in hets_files]\n",
    "    sample_ccfs = get_sample_ccfs(cluster_df, samples)\n",
    "    contig_trees = make_contig_trees(acs_dfs, samples)\n",
    "    seg_assignments, seg_total_cn, seg_allelic_cn, seg_ccf = assign_segs(contig_trees, sample_ccfs, hets_dfs, pur, plo)\n",
    "\n",
    "\n",
    "    for sample_name, purity, ploidy, seg in zip(samples, pur, plo, acs_dfs):\n",
    "            plot_absolute(sample_name, purity, ploidy, seg_assignments, contig_trees, seg,\n",
    "                          'CRC_cnv' + '/' + sample_name + '.segs.extended.png')\n",
    "\n",
    "    with open(patient + '.seg_assignments.txt', 'w') as f:\n",
    "        f.write('Chromosome\\tStart.bp\\tEnd.bp\\tCluster_assignment\\ttotal_CN\\tallelic_CN\\n')\n",
    "        for chrom in seg_assignments:\n",
    "            for seg in seg_assignments[chrom]:\n",
    "                tcn = seg_total_cn[chrom][(seg.begin, seg.end)]\n",
    "                acn = seg_allelic_cn[chrom][(seg.begin, seg.end)]\n",
    "                f.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(chrom, str(seg.begin), str(seg.end), seg.data, tcn, acn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write seg assignment file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(patient + '.seg_assignments.txt', 'w') as f:\n",
    "        f.write('Chromosome\\tStart.bp\\tEnd.bp\\tCluster_assignment\\ttotal_CN\\tallelic_CN\\n')\n",
    "        for chrom in seg_assignments:\n",
    "            for seg in seg_assignments[chrom]:\n",
    "                tcn = seg_total_cn[chrom][(seg.begin, seg.end)]\n",
    "                acn = seg_allelic_cn[chrom][(seg.begin, seg.end)]\n",
    "                f.write('{}\\t{}\\t{}\\t{}\\t{}\\t{}\\n'.format(chrom, str(seg.begin), str(seg.end), seg.data, tcn, acn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write seg CCF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('{}.seg_ccf.txt'.format('JB-0126'), 'w') as f:\n",
    "    f.write('Chromosome\\tStart\\tEnd\\tcn_a1\\tcn_a2\\t{}\\n'.format('\\t'.join(s + '_CCF' for s in samples)))\n",
    "    for chrom, seg_dict in seg_ccf.items():\n",
    "        for (start, end), sample_ccfs in seg_dict.items():\n",
    "            f.write('{}\\t{}\\t{}\\t{}\\t{}\\t'.format(chrom, start, end, seg_allelic_cn[chrom][(start, end)][0], seg_allelic_cn[chrom][(start, end)][1]))\n",
    "            f.write('\\t'.join(str(sample_ccfs[s]) for s in samples) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
